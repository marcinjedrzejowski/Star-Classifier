{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evaluateAndPrintMetricsRanking (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"utils/preprocessing.jl\")\n",
    "include(\"utils/model_evaluation.jl\")\n",
    "include(\"utils/data_loader.jl\")\n",
    "include(\"utils/visualization.jl\")\n",
    "include(\"utils/ml1_utils.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DESCRIPTION OF APPROACH ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LOAD THE DATA #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Pkg;\n",
    "# Pkg.add(\"Random\")\n",
    "using Random\n",
    "Random.seed!(123)\n",
    "\n",
    "data = DataLoader.load_data(\"dataset\\\\star_classification.csv\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (OPTIONAL) REDUCE THE DATASET #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10432×18 Matrix{Any}:\n",
       "                    \"obj_ID\"     \"alpha\"  …       \"MJD\"     \"fiber_ID\"\n",
       " 1237668331490115584          217.823        54233       171\n",
       " 1237678847184536320          329.41         55497       171\n",
       " 1237662194520752384          167.451        54943       171\n",
       " 1237679998237671936          348.675        57712       171\n",
       " 1237666339725443584           15.6284    …  58100       171\n",
       " 1237654030867366144          175.973        55677       171\n",
       " 1237663782592315904           12.6412       55201       171\n",
       " 1237667735043899392          180.531        54208       171\n",
       " 1237669761184695552          331.729        56105       171\n",
       " 1237664877804848128          148.53      …  58158       171\n",
       " 1237651538715345152          202.775        54616       171\n",
       " 1237665547826234112          238.54         55327       171\n",
       "                   ⋮                      ⋱              \n",
       " 1237663479256253184          327.55      …  55478       973\n",
       " 1237651496835547392          127.034        55182       973\n",
       " 1237658203451884032          228.817        56066       973\n",
       " 1237657630063853824          176.482        56416       973\n",
       " 1237659327096095744          231.738        56398       973\n",
       " 1237650371549593856          166.075     …  55565       973\n",
       " 1237667209978708480          150.001        56254       985\n",
       " 1237655693011714816          216.973        55333       985\n",
       " 1237661387068670720          216.013        56449       985\n",
       " 1237680272574251776          335.643        55858       985\n",
       " 1237661384386216704          153.709     …  55589       985\n",
       " 1237663916261114624          112.686        55241       985"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function reduce_data(dataset::Matrix, percentage_to_keep::Float64)\n",
    "    # Extract data and targets from the dataset\n",
    "    data = dataset[:, 1:end-1]\n",
    "    targets = dataset[:, end]\n",
    "\n",
    "    unique_classes = unique(targets)\n",
    "    reduced_data = Matrix{Float64}(undef, 0, size(data, 2))\n",
    "    reduced_targets = Vector{Float64}()\n",
    "\n",
    "    for class in unique_classes\n",
    "        # Get the data and targets for this class\n",
    "        class_data = data[targets .== class, :]\n",
    "        class_targets = targets[targets .== class]\n",
    "\n",
    "        # Calculate the number of rows to keep\n",
    "        num_rows_to_keep = Int(ceil(size(class_data, 1) * percentage_to_keep))\n",
    "\n",
    "        # Randomly select the subset of rows\n",
    "        indices = randperm(size(class_data, 1))[1:num_rows_to_keep]\n",
    "        subset_class_data = class_data[indices, :]\n",
    "        subset_class_targets = class_targets[indices]\n",
    "\n",
    "        # Append the reduced data and targets for this class to the overall reduced data and targets\n",
    "        reduced_data = vcat(reduced_data, subset_class_data)\n",
    "        reduced_targets = vcat(reduced_targets, subset_class_targets)\n",
    "    end\n",
    "\n",
    "    # Combine reduced data and targets\n",
    "    reduced_dataset = hcat(reduced_data, reduced_targets)\n",
    "\n",
    "    return reduced_dataset\n",
    "end\n",
    "\n",
    "reduced_data = reduce_data(data, 0.1)\n",
    "\n",
    "#= using StatsBase\n",
    "\n",
    "# Extract the class column from the reduced dataset\n",
    "classes = reduced_data[2:end, 14]\n",
    "\n",
    "# Count the number of rows in each class\n",
    "class_counts = countmap(classes)\n",
    "\n",
    "# Print the counts\n",
    "for (class, count) in class_counts\n",
    "    println(\"Class $class: $count rows\")\n",
    "end =#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PREPROCESSING THE DATASET #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size :(10431, 5)\n",
      "First input: Float32[19.60844, 17.82744, 16.94823, 16.51685, 16.22224]\n",
      "First target: Any[\"GALAXY\"]\n"
     ]
    }
   ],
   "source": [
    "# preprocess_data(dataset, balancing_dataset, features)\n",
    "inputs, targets = Preprocessing.preprocess_data(reduced_data, false, [4,5,6,7,8]);\n",
    "\n",
    "\"\"\"    This function does the following:\n",
    "        - Optional balancing the data using the undersampling method\n",
    "        - Parse the data: chosing the correct columns for inputs and targets\n",
    "        - Convert the input into an 2D array of floats\n",
    "\"\"\"\n",
    "\n",
    "# Print first input and target\n",
    "println(\"First input: \", inputs[1, :])\n",
    "println(\"First target: \", targets[1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### HOLDOUT #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train inputs: (7302, 5)\n",
      "Train targets: (7302,)\n",
      "Test inputs: (3129, 5)\n",
      "Test targets: (3129,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Initial holdOut split of the data\"\"\"\n",
    "\n",
    "N = size(inputs, 1)\n",
    "\n",
    "# Split to train and test using the holdOut function\n",
    "train_indices, test_indices = holdOut(N, 0.3)\n",
    "\n",
    "\"\"\"   This function does the following:\n",
    "        - Split the data into train and test sets\n",
    "        - Returns the indices of the train and test sets\n",
    "\"\"\"\n",
    "\n",
    "# Extract training and testing data\n",
    "train_inputs = inputs[train_indices, :]\n",
    "train_targets = targets[train_indices]\n",
    "test_inputs = inputs[test_indices, :]\n",
    "test_targets = targets[test_indices]\n",
    "\n",
    "# Check size of train and test sets\n",
    "println(\"Train inputs: \", size(train_inputs))\n",
    "println(\"Train targets: \", size(train_targets))\n",
    "println(\"Test inputs: \", size(test_inputs))\n",
    "println(\"Test targets: \", size(test_targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NORMALIZATION #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First train inputs: Float32[0.36424, 0.45762557, 0.4814966, 0.4386007, 0.45649394]\n",
      "First test inputs: Float32[0.43858442, 0.42200762, 0.4093346, 0.4031706, 0.37274083]\n"
     ]
    }
   ],
   "source": [
    "train_inputs = Preprocessing.normalize_data(train_inputs, \"minmax\")\n",
    "test_inputs = Preprocessing.normalize_data(test_inputs, \"minmax\")\n",
    "\n",
    "\"\"\"    This function does the following:\n",
    "        - Normalize the input data using the minmax method (\"minmax\")\n",
    "            or the zero mean method (\"zeromean\")\n",
    "\"\"\"\n",
    "\n",
    "println(\"First train inputs: \", train_inputs[1, :])\n",
    "println(\"First test inputs: \", test_inputs[1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing hyperparameters for each model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ScikitLearn\n",
    "\n",
    "@sk_import neural_network: MLPClassifier;\n",
    "@sk_import svm: SVC;\n",
    "@sk_import tree: DecisionTreeClassifier;\n",
    "@sk_import neighbors: KNeighborsClassifier;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Setting indices for the k-fold cross-validation\n",
    "    we are about to do with the different models\n",
    "\"\"\"\n",
    "N=size(train_inputs,1)\n",
    "k = 5 # number of folds\n",
    "kFoldIndices = crossvalidation(N, k);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DECISION TREE #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with set of hyperparameters 1\n",
      "Training with set of hyperparameters 2\n",
      "Training with set of hyperparameters 3\n",
      "Training with set of hyperparameters 4\n",
      "Training with set of hyperparameters 5\n",
      "Training with set of hyperparameters 6\n",
      "\n",
      "----- acc -----\n",
      "Set of hyperparameters 3 -> mean: 0.801 Std. Dev.: 0.013\n",
      "Set of hyperparameters 4 -> mean: 0.779 Std. Dev.: 0.009\n",
      "Set of hyperparameters 5 -> mean: 0.778 Std. Dev.: 0.01\n",
      "Set of hyperparameters 6 -> mean: 0.778 Std. Dev.: 0.01\n",
      "Set of hyperparameters 2 -> mean: 0.758 Std. Dev.: 0.003\n",
      "Set of hyperparameters 1 -> mean: 0.72 Std. Dev.: 0.004\n",
      "\n",
      "----- sensitivity -----\n",
      "Set of hyperparameters 3 -> mean: 0.801 Std. Dev.: 0.013\n",
      "Set of hyperparameters 4 -> mean: 0.779 Std. Dev.: 0.009\n",
      "Set of hyperparameters 5 -> mean: 0.778 Std. Dev.: 0.01\n",
      "Set of hyperparameters 6 -> mean: 0.778 Std. Dev.: 0.01\n",
      "Set of hyperparameters 2 -> mean: 0.758 Std. Dev.: 0.003\n",
      "Set of hyperparameters 1 -> mean: 0.72 Std. Dev.: 0.004\n",
      "\n",
      "----- specificity -----\n",
      "Set of hyperparameters 5 -> mean: 0.843 Std. Dev.: 0.009\n",
      "Set of hyperparameters 6 -> mean: 0.843 Std. Dev.: 0.009\n",
      "Set of hyperparameters 3 -> mean: 0.842 Std. Dev.: 0.017\n",
      "Set of hyperparameters 4 -> mean: 0.84 Std. Dev.: 0.006\n",
      "Set of hyperparameters 2 -> mean: 0.775 Std. Dev.: 0.011\n",
      "Set of hyperparameters 1 -> mean: 0.744 Std. Dev.: 0.009\n",
      "\n",
      "----- ppv -----\n",
      "Set of hyperparameters 3 -> mean: 0.796 Std. Dev.: 0.015\n",
      "Set of hyperparameters 5 -> mean: 0.779 Std. Dev.: 0.011\n",
      "Set of hyperparameters 6 -> mean: 0.779 Std. Dev.: 0.011\n",
      "Set of hyperparameters 4 -> mean: 0.779 Std. Dev.: 0.009\n",
      "Set of hyperparameters 2 -> mean: 0.738 Std. Dev.: 0.002\n",
      "Set of hyperparameters 1 -> mean: 0.725 Std. Dev.: 0.036\n",
      "\n",
      "----- npv -----\n",
      "Set of hyperparameters 3 -> mean: 0.871 Std. Dev.: 0.006\n",
      "Set of hyperparameters 1 -> mean: 0.867 Std. Dev.: 0.01\n",
      "Set of hyperparameters 2 -> mean: 0.866 Std. Dev.: 0.015\n",
      "Set of hyperparameters 4 -> mean: 0.845 Std. Dev.: 0.009\n",
      "Set of hyperparameters 5 -> mean: 0.842 Std. Dev.: 0.008\n",
      "Set of hyperparameters 6 -> mean: 0.842 Std. Dev.: 0.008\n",
      "\n",
      "----- f_score -----\n",
      "Set of hyperparameters 3 -> mean: 0.797 Std. Dev.: 0.015\n",
      "Set of hyperparameters 4 -> mean: 0.779 Std. Dev.: 0.009\n",
      "Set of hyperparameters 5 -> mean: 0.778 Std. Dev.: 0.01\n",
      "Set of hyperparameters 6 -> mean: 0.778 Std. Dev.: 0.01\n",
      "Set of hyperparameters 2 -> mean: 0.739 Std. Dev.: 0.002\n",
      "Set of hyperparameters 1 -> mean: 0.648 Std. Dev.: 0.014\n",
      "\n",
      "----- err_rate -----\n",
      "Set of hyperparameters 3 -> mean: 0.199 Std. Dev.: 0.013\n",
      "Set of hyperparameters 4 -> mean: 0.221 Std. Dev.: 0.009\n",
      "Set of hyperparameters 5 -> mean: 0.222 Std. Dev.: 0.01\n",
      "Set of hyperparameters 6 -> mean: 0.222 Std. Dev.: 0.01\n",
      "Set of hyperparameters 2 -> mean: 0.242 Std. Dev.: 0.003\n",
      "Set of hyperparameters 1 -> mean: 0.28 Std. Dev.: 0.004\n"
     ]
    }
   ],
   "source": [
    "# Define an array of hyperparameter dictionaries for the Decision Tree model\n",
    "dtree_hyperparameters_array = [\n",
    "    Dict(\"max_depth\" => 3),\n",
    "    Dict(\"max_depth\" => 5),\n",
    "    Dict(\"max_depth\" => 10),\n",
    "    Dict(\"max_depth\" => 20),\n",
    "    Dict(\"max_depth\" => 50),\n",
    "    Dict(\"max_depth\" => 100) # Deeper trees can capture more detail but risk overfitting\n",
    "]\n",
    "\n",
    "# Call the function to evaluate the model using different sets of hyperparameters and print the ranking of metrics.\n",
    "evaluateAndPrintMetricsRanking(:DecisionTree,dtree_hyperparameters_array, train_inputs, train_targets, kFoldIndices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### kNN #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with set of hyperparameters 1\n",
      "Training with set of hyperparameters 2\n",
      "Training with set of hyperparameters 3\n",
      "Training with set of hyperparameters 4\n",
      "Training with set of hyperparameters 5\n",
      "Training with set of hyperparameters 6\n",
      "\n",
      "----- acc -----\n",
      "Set of hyperparameters 1 -> mean: 0.828 Std. Dev.: 0.008\n",
      "Set of hyperparameters 2 -> mean: 0.822 Std. Dev.: 0.01\n",
      "Set of hyperparameters 3 -> mean: 0.815 Std. Dev.: 0.009\n",
      "Set of hyperparameters 4 -> mean: 0.809 Std. Dev.: 0.011\n",
      "Set of hyperparameters 5 -> mean: 0.791 Std. Dev.: 0.007\n",
      "Set of hyperparameters 6 -> mean: 0.783 Std. Dev.: 0.006\n",
      "\n",
      "----- sensitivity -----\n",
      "Set of hyperparameters 1 -> mean: 0.828 Std. Dev.: 0.008\n",
      "Set of hyperparameters 2 -> mean: 0.822 Std. Dev.: 0.01\n",
      "Set of hyperparameters 3 -> mean: 0.815 Std. Dev.: 0.009\n",
      "Set of hyperparameters 4 -> mean: 0.809 Std. Dev.: 0.011\n",
      "Set of hyperparameters 5 -> mean: 0.791 Std. Dev.: 0.007\n",
      "Set of hyperparameters 6 -> mean: 0.783 Std. Dev.: 0.006\n",
      "\n",
      "----- specificity -----\n",
      "Set of hyperparameters 1 -> mean: 0.855 Std. Dev.: 0.012\n",
      "Set of hyperparameters 2 -> mean: 0.842 Std. Dev.: 0.012\n",
      "Set of hyperparameters 3 -> mean: 0.839 Std. Dev.: 0.011\n",
      "Set of hyperparameters 4 -> mean: 0.829 Std. Dev.: 0.014\n",
      "Set of hyperparameters 5 -> mean: 0.812 Std. Dev.: 0.006\n",
      "Set of hyperparameters 6 -> mean: 0.804 Std. Dev.: 0.006\n",
      "\n",
      "----- ppv -----\n",
      "Set of hyperparameters 1 -> mean: 0.824 Std. Dev.: 0.01\n",
      "Set of hyperparameters 2 -> mean: 0.816 Std. Dev.: 0.012\n",
      "Set of hyperparameters 3 -> mean: 0.809 Std. Dev.: 0.011\n",
      "Set of hyperparameters 4 -> mean: 0.802 Std. Dev.: 0.013\n",
      "Set of hyperparameters 5 -> mean: 0.782 Std. Dev.: 0.009\n",
      "Set of hyperparameters 6 -> mean: 0.774 Std. Dev.: 0.007\n",
      "\n",
      "----- npv -----\n",
      "Set of hyperparameters 2 -> mean: 0.9 Std. Dev.: 0.008\n",
      "Set of hyperparameters 1 -> mean: 0.899 Std. Dev.: 0.008\n",
      "Set of hyperparameters 3 -> mean: 0.893 Std. Dev.: 0.011\n",
      "Set of hyperparameters 4 -> mean: 0.89 Std. Dev.: 0.011\n",
      "Set of hyperparameters 5 -> mean: 0.88 Std. Dev.: 0.014\n",
      "Set of hyperparameters 6 -> mean: 0.878 Std. Dev.: 0.015\n",
      "\n",
      "----- f_score -----\n",
      "Set of hyperparameters 1 -> mean: 0.823 Std. Dev.: 0.01\n",
      "Set of hyperparameters 2 -> mean: 0.814 Std. Dev.: 0.012\n",
      "Set of hyperparameters 3 -> mean: 0.808 Std. Dev.: 0.011\n",
      "Set of hyperparameters 4 -> mean: 0.799 Std. Dev.: 0.013\n",
      "Set of hyperparameters 5 -> mean: 0.779 Std. Dev.: 0.007\n",
      "Set of hyperparameters 6 -> mean: 0.768 Std. Dev.: 0.005\n",
      "\n",
      "----- err_rate -----\n",
      "Set of hyperparameters 1 -> mean: 0.172 Std. Dev.: 0.008\n",
      "Set of hyperparameters 2 -> mean: 0.178 Std. Dev.: 0.01\n",
      "Set of hyperparameters 3 -> mean: 0.185 Std. Dev.: 0.009\n",
      "Set of hyperparameters 4 -> mean: 0.191 Std. Dev.: 0.011\n",
      "Set of hyperparameters 5 -> mean: 0.209 Std. Dev.: 0.007\n",
      "Set of hyperparameters 6 -> mean: 0.217 Std. Dev.: 0.006\n"
     ]
    }
   ],
   "source": [
    "# Define an array of hyperparameter dictionaries for the kNN model\n",
    "knn_hyperparameters_array = [\n",
    "    Dict(\"n_neighbors\" => 5),\n",
    "    Dict(\"n_neighbors\" => 10),\n",
    "    Dict(\"n_neighbors\" => 15),\n",
    "    Dict(\"n_neighbors\" => 20),\n",
    "    Dict(\"n_neighbors\" => 50),\n",
    "    Dict(\"n_neighbors\" => 100) # Large neighborhoods, smooths out predictions\n",
    "]\n",
    "\n",
    "# Call the function to evaluate the model using different sets of hyperparameters and print the ranking of metrics.\n",
    "evaluateAndPrintMetricsRanking(:kNN,knn_hyperparameters_array, train_inputs, train_targets, kFoldIndices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ANN #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with set of hyperparameters 1\n",
      "Training with set of hyperparameters 2\n",
      "Training with set of hyperparameters 3\n",
      "Training with set of hyperparameters 4\n",
      "Training with set of hyperparameters 5\n",
      "Training with set of hyperparameters 6\n",
      "Training with set of hyperparameters 7\n",
      "Training with set of hyperparameters 8\n",
      "\n",
      "----- acc -----\n",
      "Set of hyperparameters 1 -> mean: 0.817 Std. Dev.: 0.009\n",
      "Set of hyperparameters 2 -> mean: 0.785 Std. Dev.: 0.009\n",
      "Set of hyperparameters 3 -> mean: 0.775 Std. Dev.: 0.007\n",
      "Set of hyperparameters 6 -> mean: 0.758 Std. Dev.: 0.011\n",
      "Set of hyperparameters 7 -> mean: 0.735 Std. Dev.: 0.007\n",
      "Set of hyperparameters 5 -> mean: 0.707 Std. Dev.: 0.01\n",
      "Set of hyperparameters 4 -> mean: 0.692 Std. Dev.: 0.007\n",
      "Set of hyperparameters 8 -> mean: 0.592 Std. Dev.: 0.007\n",
      "\n",
      "----- sensitivity -----\n",
      "Set of hyperparameters 1 -> mean: 0.817 Std. Dev.: 0.009\n",
      "Set of hyperparameters 2 -> mean: 0.785 Std. Dev.: 0.009\n",
      "Set of hyperparameters 3 -> mean: 0.775 Std. Dev.: 0.007\n",
      "Set of hyperparameters 6 -> mean: 0.758 Std. Dev.: 0.011\n",
      "Set of hyperparameters 7 -> mean: 0.735 Std. Dev.: 0.007\n",
      "Set of hyperparameters 5 -> mean: 0.707 Std. Dev.: 0.01\n",
      "Set of hyperparameters 4 -> mean: 0.692 Std. Dev.: 0.007\n",
      "Set of hyperparameters 8 -> mean: 0.592 Std. Dev.: 0.007\n",
      "\n",
      "----- specificity -----\n",
      "Set of hyperparameters 1 -> mean: 0.839 Std. Dev.: 0.007\n",
      "Set of hyperparameters 2 -> mean: 0.811 Std. Dev.: 0.01\n",
      "Set of hyperparameters 3 -> mean: 0.786 Std. Dev.: 0.007\n",
      "Set of hyperparameters 6 -> mean: 0.761 Std. Dev.: 0.012\n",
      "Set of hyperparameters 7 -> mean: 0.696 Std. Dev.: 0.009\n",
      "Set of hyperparameters 5 -> mean: 0.684 Std. Dev.: 0.008\n",
      "Set of hyperparameters 4 -> mean: 0.665 Std. Dev.: 0.01\n",
      "Set of hyperparameters 8 -> mean: 0.408 Std. Dev.: 0.006\n",
      "\n",
      "----- ppv -----\n",
      "Set of hyperparameters 1 -> mean: 0.813 Std. Dev.: 0.012\n",
      "Set of hyperparameters 2 -> mean: 0.777 Std. Dev.: 0.009\n",
      "Set of hyperparameters 3 -> mean: 0.769 Std. Dev.: 0.01\n",
      "Set of hyperparameters 4 -> mean: 0.759 Std. Dev.: 0.003\n",
      "Set of hyperparameters 6 -> mean: 0.753 Std. Dev.: 0.014\n",
      "Set of hyperparameters 7 -> mean: 0.711 Std. Dev.: 0.008\n",
      "Set of hyperparameters 5 -> mean: 0.681 Std. Dev.: 0.026\n",
      "Set of hyperparameters 8 -> mean: 0.625 Std. Dev.: 0.08\n",
      "\n",
      "----- npv -----\n",
      "Set of hyperparameters 1 -> mean: 0.897 Std. Dev.: 0.012\n",
      "Set of hyperparameters 3 -> mean: 0.884 Std. Dev.: 0.013\n",
      "Set of hyperparameters 2 -> mean: 0.876 Std. Dev.: 0.01\n",
      "Set of hyperparameters 7 -> mean: 0.868 Std. Dev.: 0.01\n",
      "Set of hyperparameters 6 -> mean: 0.865 Std. Dev.: 0.008\n",
      "Set of hyperparameters 5 -> mean: 0.835 Std. Dev.: 0.011\n",
      "Set of hyperparameters 4 -> mean: 0.821 Std. Dev.: 0.013\n",
      "Set of hyperparameters 8 -> mean: 0.614 Std. Dev.: 0.188\n",
      "\n",
      "----- f_score -----\n",
      "Set of hyperparameters 1 -> mean: 0.808 Std. Dev.: 0.011\n",
      "Set of hyperparameters 2 -> mean: 0.769 Std. Dev.: 0.012\n",
      "Set of hyperparameters 3 -> mean: 0.751 Std. Dev.: 0.008\n",
      "Set of hyperparameters 6 -> mean: 0.728 Std. Dev.: 0.017\n",
      "Set of hyperparameters 7 -> mean: 0.685 Std. Dev.: 0.011\n",
      "Set of hyperparameters 5 -> mean: 0.63 Std. Dev.: 0.017\n",
      "Set of hyperparameters 4 -> mean: 0.608 Std. Dev.: 0.01\n",
      "Set of hyperparameters 8 -> mean: 0.441 Std. Dev.: 0.008\n",
      "\n",
      "----- err_rate -----\n",
      "Set of hyperparameters 1 -> mean: 0.183 Std. Dev.: 0.009\n",
      "Set of hyperparameters 2 -> mean: 0.215 Std. Dev.: 0.009\n",
      "Set of hyperparameters 3 -> mean: 0.225 Std. Dev.: 0.007\n",
      "Set of hyperparameters 6 -> mean: 0.242 Std. Dev.: 0.011\n",
      "Set of hyperparameters 7 -> mean: 0.265 Std. Dev.: 0.007\n",
      "Set of hyperparameters 5 -> mean: 0.293 Std. Dev.: 0.01\n",
      "Set of hyperparameters 4 -> mean: 0.308 Std. Dev.: 0.007\n",
      "Set of hyperparameters 8 -> mean: 0.408 Std. Dev.: 0.007\n"
     ]
    }
   ],
   "source": [
    "svm_hyperparameters_array = [\n",
    "    # Uses 'rbf' kernel, medium complexity with C=1.0, default polynomial degree, 'scale' for gamma \n",
    "    Dict(\"kernel\" => \"rbf\", \"degree\" => 3, \"C\" => 1.0, \"gamma\" => \"scale\"),\n",
    "    \n",
    "    # Same 'rbf' kernel, increased penalty (C=10.0) for larger-margin separation, 'auto' gamma adjusts based on features\n",
    "    Dict(\"kernel\" => \"rbf\", \"degree\" => 3, \"C\" => 10.0, \"gamma\" => \"auto\"),\n",
    "    \n",
    "    # Same 'rbf' kernel, lower penalty (C=0.1) for a softer-margin, 'scale' gamma is default scaling\n",
    "    Dict(\"kernel\" => \"rbf\", \"degree\" => 3, \"C\" => 0.1, \"gamma\" => \"scale\"),\n",
    "\n",
    "    # 'linear' kernel, suitable for less complex data\n",
    "    Dict(\"kernel\" => \"linear\", \"degree\" => 5,  \"C\" => 0.1, \"gamma\" => \"auto\"),\n",
    "    \n",
    "    # 'linear' kernel, not affected by 'degree' or 'gamma', with C=1.0 indicating a balance between margin and misclassification\n",
    "    Dict(\"kernel\" => \"linear\", \"degree\" => 3, \"C\" => 1.0, \"gamma\" => \"auto\"),\n",
    "\n",
    "    # 'linear' kernel with a higher penalty, stricter margin\n",
    "    Dict(\"kernel\" => \"linear\", \"degree\" => 7, \"C\" => 10.0, \"gamma\" => \"scale\"),\n",
    "    \n",
    "    # 'poly' kernel, polynomial degree is set twice by mistake, should only be 'degree' => 3, 'scale' gamma defaults to feature scale\n",
    "    Dict(\"kernel\" => \"poly\", \"degree\" => 3, \"C\" => 1.0, \"gamma\" => \"scale\"),\n",
    "    \n",
    "    # 'poly' kernel, increased polynomial degree (5) for higher model complexity, 'auto' gamma may overfit with high dimension\n",
    "    Dict(\"kernel\" => \"poly\", \"degree\" => 5, \"C\" => 1.0, \"gamma\" => \"auto\")\n",
    "]\n",
    "\n",
    "\n",
    "# Call the function to evaluate the model using different sets of hyperparameters and print the ranking of metrics.\n",
    "evaluateAndPrintMetricsRanking(:SVM, svm_hyperparameters_array, train_inputs, train_targets, kFoldIndices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
