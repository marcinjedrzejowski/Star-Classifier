{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Main.Preprocessing"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"utils/data_loader.jl\")\n",
    "include(\"utils/visualization.jl\")\n",
    "include(\"utils/preprocessing.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APPROACH 1: Without Balancing ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Pkg;\n",
    "# Pkg.add(\"Random\")\n",
    "using Random\n",
    "Random.seed!(123)\n",
    "\n",
    "data = DataLoader.load_data(\"dataset\\\\star_classification.csv\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocess and balancing data #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size :(56883, 5)\n",
      "First input: Float32[23.12955, 22.98013, 21.18687, 20.26653, 19.87306]\n",
      "First target: Bool[1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# preprocess_data(dataset, balancing_dataset, normalization, features)\n",
    "inputs, targets = Preprocessing.preprocess_data(data, true, [4,5,6,7,8]);\n",
    "\n",
    "# Print first input and target\n",
    "println(\"First input: \", inputs[1, :])\n",
    "println(\"First target: \", targets[1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split to train and test\n",
    "# train_inputs, train_targets, test_inputs, test_targets = DataLoader.split_data(inputs, targets, 0.8);\n",
    "# Check size of train and test sets\n",
    "# println(\"Train inputs: \", size(train_inputs))\n",
    "# println(\"Train targets: \", size(train_targets))\n",
    "# println(\"Test inputs: \", size(test_inputs))\n",
    "# println(\"Test targets: \", size(test_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train inputs: Float32[0.9990379, 0.99914044, 0.5812591, 0.47621873, 0.9991107]\n"
     ]
    }
   ],
   "source": [
    "# Normalize data\n",
    "train_inputs = Preprocessing.normalize_data(inputs , \"minmax\");\n",
    "println(\"Train inputs: \", train_inputs[1, :])\n",
    "# println(\"Train targets: \", train_targets[1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crossvalidation indices: [6, 4, 10, 7, 4, 7, 8, 1, 4, 9, 10, 10, 3, 5, 4, 4, 1, 6, 1, 4, 9, 1, 5, 5, 9, 5, 2, 10, 8, 6, 10, 4, 1, 2, 1, 2, 10, 9, 10, 6, 5, 8, 1, 10, 6, 9, 6, 2, 9, 1, 6, 9, 1, 3, 10, 7, 5, 2, 3, 7, 9, 4, 5, 8, 4, 2, 3, 5, 7, 9, 1, 5, 2, 8, 3, 1, 7, 6, 2, 3, 5, 9, 5, 1, 7, 2, 2, 9, 7, 2, 2, 1, 6, 5, 6, 1, 2, 4, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "# println(\"Train inputs: \", size(train_targets))\n",
    "training_indices = Preprocessing.crossvalidation(targets, 10)\n",
    "println(\"Crossvalidation indices: \", training_indices[1:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### EVALUATING KNN'S DIFFERENT PARAMETERS #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_and_evaluate_knn_hyperparameters (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using ScikitLearn\n",
    "using Statistics\n",
    "\n",
    "@sk_import neighbors: KNeighborsClassifier\n",
    "\n",
    "function train_and_evaluate_knn_hyperparameters(k_values::AbstractVector{Int}, trainingDataset::Tuple{Matrix{Float32}, BitMatrix}, kFoldIndices::Array{Int64,1})\n",
    "    numFolds = maximum(kFoldIndices)\n",
    "    (inputs, targets) = trainingDataset\n",
    "\n",
    "    testAccuracies = Float64[]\n",
    "\n",
    "    for k_val in k_values\n",
    "        knn_model = KNeighborsClassifier(n_neighbors=k_val)\n",
    "\n",
    "        fold_accuracies = Float64[]\n",
    "\n",
    "        for numFold in 1:numFolds\n",
    "            trainingInputs = inputs[kFoldIndices .!= numFold, :]\n",
    "            testingInputs = inputs[kFoldIndices .== numFold, :]\n",
    "            trainingTargets = targets[kFoldIndices .!= numFold, :]\n",
    "            testingTargets = targets[kFoldIndices .== numFold, :]\n",
    "\n",
    "            _, trained_model = Preprocessing.oneVSall(knn_model, trainingInputs, trainingTargets)\n",
    "            predictions = predict(trained_model, testingInputs)\n",
    "            accuracy = sum(predictions .== testingTargets) / length(testingTargets)\n",
    "            push!(fold_accuracies, accuracy)\n",
    "        end\n",
    "\n",
    "        mean_accuracy = mean(fold_accuracies)\n",
    "        push!(testAccuracies, mean_accuracy)\n",
    "\n",
    "        println(\"KNN with k=$k_val - Mean Accuracy: $mean_accuracy\")\n",
    "    end\n",
    "\n",
    "    best_k = argmax(testAccuracies)\n",
    "    best_accuracy = testAccuracies[best_k]\n",
    "\n",
    "    println(\"Best KNN Model - k=$(k_values[best_k]) - Best Mean Accuracy: $best_accuracy\")\n",
    "\n",
    "    return k_values[best_k]\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6-element Vector{Int64}:\n",
       "  3\n",
       "  5\n",
       "  7\n",
       "  9\n",
       " 11\n",
       " 13"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_values_to_try = [3, 5, 7, 9, 11, 13]\n",
    "# best_k = train_and_evaluate_knn_hyperparameters(k_values_to_try, (train_inputs, targets), training_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### EVALUATING DECISION TREE'S HYPERPARAMETERS #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_and_evaluate_decision_tree_hyperparameters (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using ScikitLearn\n",
    "using Statistics\n",
    "\n",
    "@sk_import tree: DecisionTreeClassifier\n",
    "\n",
    "function train_and_evaluate_decision_tree_hyperparameters(max_depth_values::AbstractVector{Int}, trainingDataset::Tuple{Matrix{Float32}, BitMatrix}, kFoldIndices::Array{Int64,1})\n",
    "    numFolds = maximum(kFoldIndices)\n",
    "    (inputs, targets) = trainingDataset\n",
    "\n",
    "    testAccuracies = Float64[]\n",
    "\n",
    "    for max_depth_val in max_depth_values\n",
    "        dt_model = DecisionTreeClassifier(max_depth=max_depth_val)\n",
    "\n",
    "        fold_accuracies = Float64[]\n",
    "\n",
    "        for numFold in 1:numFolds\n",
    "            trainingInputs = inputs[kFoldIndices .!= numFold, :]\n",
    "            testingInputs = inputs[kFoldIndices .== numFold, :]\n",
    "            trainingTargets = targets[kFoldIndices .!= numFold, :]\n",
    "            testingTargets = targets[kFoldIndices .== numFold, :]\n",
    "\n",
    "            _, trained_model = Preprocessing.oneVSall(dt_model, trainingInputs, trainingTargets)\n",
    "            predictions = predict(trained_model, testingInputs)\n",
    "            accuracy = sum(predictions .== testingTargets) / length(testingTargets)\n",
    "            push!(fold_accuracies, accuracy)\n",
    "        end\n",
    "\n",
    "        mean_accuracy = mean(fold_accuracies)\n",
    "        push!(testAccuracies, mean_accuracy)\n",
    "\n",
    "        println(\"Decision Tree with max_depth=$max_depth_val - Mean Accuracy: $mean_accuracy\")\n",
    "    end\n",
    "\n",
    "    best_depth = argmax(testAccuracies)\n",
    "    best_accuracy = testAccuracies[best_depth]\n",
    "\n",
    "    println(\"Best Decision Tree Model - max_depth=$(max_depth_values[best_depth]) - Best Mean Accuracy: $best_accuracy\")\n",
    "\n",
    "    return max_depth_values[best_depth]\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6-element Vector{Int64}:\n",
       "  3\n",
       "  5\n",
       "  7\n",
       "  9\n",
       " 11\n",
       " 13"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_depth_values_to_try = [3, 5, 7, 9, 11, 13]\n",
    "# best_max_depth = train_and_evaluate_decision_tree_hyperparameters(max_depth_values_to_try, (train_inputs, targets), training_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### EVALUATING SVM'S HYPERPARAMETERS #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: redefinition of constant SVC. This may fail, cause incorrect answers, or produce other errors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "train_and_evaluate_svm_hyperparameters (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using ScikitLearn\n",
    "using Statistics\n",
    "using PyCall\n",
    "\n",
    "@sk_import svm: SVC\n",
    "\n",
    "function train_and_evaluate_svm_hyperparameters(kernels::AbstractVector{String}, c_values::AbstractVector{Float64}, trainingDataset::Tuple{Matrix{Float32}, BitMatrix}, kFoldIndices::Array{Int64,1})\n",
    "    numFolds = maximum(kFoldIndices)\n",
    "    (inputs, targets) = trainingDataset\n",
    "\n",
    "    testAccuracies = Float64[]\n",
    "    println(\"Kernels: $kernels\")\n",
    "    println(\"C values: $c_values\")\n",
    "    \n",
    "    println(\"First check.\")\n",
    "    for kernel_val in kernels\n",
    "        println(\"Second check.\")\n",
    "        for c_val in c_values\n",
    "            println(\"Training SVM with kernel=$kernel_val, C=$c_val\")\n",
    "            # svm = pyimport(\"sklearn.svm\")\n",
    "            println(\"Third check.\")\n",
    "            # svc = svm.SVC(C=c_val, kernel=kernel_val)\n",
    "            svc = SVC(C=c_val, kernel=kernel_val)\n",
    "            println(\"Fourth check.\")\n",
    "\n",
    "            fold_accuracies = Float64[]\n",
    "            println(\"Fifth check.\")\n",
    "            for numFold in 1:numFolds\n",
    "                println(\"Starting training.\")\n",
    "                trainingInputs = inputs[kFoldIndices .!= numFold, :]\n",
    "                testingInputs = inputs[kFoldIndices .== numFold, :]\n",
    "                trainingTargets = targets[kFoldIndices .!= numFold, :]\n",
    "                testingTargets = targets[kFoldIndices .== numFold, :]\n",
    "\n",
    "                _, trained_model = Preprocessing.oneVSall(svc, trainingInputs, trainingTargets)\n",
    "                println(\"Training done, numFold: $numFold\")\n",
    "                predictions = predict(trained_model, testingInputs)\n",
    "                accuracy = sum(predictions .== testingTargets) / length(testingTargets)\n",
    "                push!(fold_accuracies, accuracy)\n",
    "            end\n",
    "\n",
    "            mean_accuracy = mean(fold_accuracies)\n",
    "            push!(testAccuracies, mean_accuracy)\n",
    "\n",
    "            println(\"SVM with kernel=$kernel_val, C=$c_val - Mean Accuracy: $mean_accuracy\")\n",
    "        end\n",
    "    end\n",
    "\n",
    "    best_idx = argmax(testAccuracies)\n",
    "    best_accuracy = testAccuracies[best_idx]\n",
    "    best_kernel_idx, best_c_idx = divrem(best_idx - 1, length(c_values))\n",
    "\n",
    "    best_kernel = kernels[best_kernel_idx + 1]\n",
    "    best_c = c_values[best_c_idx + 1]\n",
    "\n",
    "    println(\"Best SVM Model - Kernel: $best_kernel, C: $best_c - Best Mean Accuracy: $best_accuracy\")\n",
    "\n",
    "    return best_kernel, best_c\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernels: [\"rbf\", \"linear\", \"poly\"]\n",
      "C values: [1.0, 20.0, 10.0, 5.0, 2.0, 50.0, 0.5, 0.1]\n",
      "First check.\n",
      "Second check.\n",
      "Training SVM with kernel=rbf, C=1.0\n",
      "Third check."
     ]
    }
   ],
   "source": [
    "kernels_to_try = [\"rbf\", \"linear\", \"poly\"]\n",
    "c_values_to_try = [1.0, 20.0, 10.0, 5.0, 2.0, 50.0, 0.5, 0.1]\n",
    "\n",
    "best_kernel, best_c = train_and_evaluate_svm_hyperparameters(kernels_to_try, c_values_to_try, (train_inputs, targets), training_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#= using ScikitLearn\n",
    "\n",
    "@sk_import svm: SVC\n",
    "@sk_import tree: DecisionTreeClassifier\n",
    "@sk_import neighbors: KNeighborsClassifier\n",
    "\n",
    "function train_model(estimators::AbstractArray{Symbol,1},\n",
    "                    modelsHyperParameters::AbstractArray{Dict{String,Any},1},\n",
    "                    trainingDataset::Tuple{Matrix{Float32}, BitMatrix},\n",
    "                    kFoldIndices::Array{Int64,1})\n",
    "    \n",
    "    numFolds = maximum(kFoldIndices)\n",
    "    (inputs, targets) = trainingDataset\n",
    "\n",
    "    testAccuracies = Array{Float64}(undef, numFolds);\n",
    "\n",
    "    for numFold in 1:numFolds\n",
    "        trainingInputs = inputs[kFoldIndices .!= numFold, :];\n",
    "        testingInputs = inputs[kFoldIndices .== numFold, :];\n",
    "        trainingTargets = targets[kFoldIndices .!= numFold, :];\n",
    "        testingTargets = targets[kFoldIndices .== numFold, :];\n",
    "        \n",
    "        #Define the models to train\n",
    "        models = Dict(\"SVM\" => SVC(probability=modelsHyperParameters[1][\"probability\"], kernel=modelsHyperParameters[1][\"kernel\"], C=modelsHyperParameters[1][\"C\"]), \n",
    "                \"DT\" => DecisionTreeClassifier(max_depth=modelsHyperParameters[2][\"max_depth\"]),\n",
    "                \"KNN\" => KNeighborsClassifier(n_neighbors=modelsHyperParameters[3][\"n_neighbors\"][1]))\n",
    "\n",
    "        # base_models = [name for name in keys(models)]\n",
    "        # base_models = values(models)\n",
    "\n",
    "        # test each model \n",
    "        model = values(models[\"KNN\"])\n",
    "\n",
    "        final_outputs, trained_model = Preprocessing.oneVSall(model, trainingInputs, trainingTargets)\n",
    "        predictions = predict(trained_model, testingInputs)\n",
    "        # println(\"Size of final_outputs: \", size(final_outputs))\n",
    "        # println(\"Size of trainingTargets: \", size(trainingTargets))\n",
    "        (Sensitivity, Specificity, PPV, NPV, F1, Accuracy, WeightedSensitivity, WeightedSpecificity, WeightedPPV, WeightedNPV, WeightedF1, WeightedAccuracy) = Preprocessing.confusionMatrix(predictions, testingTargets)\n",
    "        println(\"NumFold: \", numFold)\n",
    "        println(\"MacroAccuracy: \", WeightedAccuracy)\n",
    "    end\n",
    "end =#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#= modelsHyperParameters = Array{Dict{String, Any}}(undef, 3)\n",
    "modelsHyperParameters[1] = Dict(\"probability\" => true, \"kernel\" => \"linear\", \"C\" => 0.1)\n",
    "modelsHyperParameters[2] = Dict(\"max_depth\" => 4)\n",
    "modelsHyperParameters[3] = Dict(\"n_neighbors\" => [1, 3, 5, 7, 9, 11])\n",
    "\n",
    "ensemble_accuracy = train_model([:SVM, :DT, :KNN], modelsHyperParameters, (inputs, targets), training_indices)=#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
